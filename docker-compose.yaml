name: lightrag

services:
  # Caddy Reverse Proxy with Docker Provider
  proxy:
    # ref1: https://hub.docker.com/_/caddy
    # ref2: https://hub.docker.com/r/lucaslorentz/caddy-docker-proxy, https://github.com/lucaslorentz/caddy-docker-proxy
    image: lucaslorentz/caddy-docker-proxy:latest
    container_name: proxy
    restart: unless-stopped
    ports:
      - 80:80
      - 443:443/tcp
      - 443:443/udp
    env_file:
      - .env.caddy
    volumes:
      # access to docker socket for capturing services config
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - caddy_data:/data
      - caddy_config:/config
      - ./docker/ssl:/certificates:ro
    networks:
      - frontend
      - backend
    labels:
      caddy: "https://dev.localhost"
      caddy.respond: "/health \"OK\" 200"
      caddy.respond_1: "/debug \"Environment: local.dev development\" 200"
      caddy.respond_2: "/* \"LightRAG Local Development Stack\" 200"
      caddy.tls: "/certificates/dev.localhost.pem /certificates/dev.localhost-key.pem"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: [ "CMD", "/bin/caddy", "validate", "--config", "/config/caddy/Caddyfile" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # LazyDocker Web UI - Docker Fleet Management
  monitor:
    # ref1: https://hub.docker.com/r/mosswill/isaiah
    # ref2: https://github.com/will-moss/isaiah
    image: ghcr.io/will-moss/isaiah:latest
    container_name: monitor
    restart: unless-stopped
    env_file:
      - .env
      - .env.monitoring
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - frontend
      - backend
    ports:
      - 3080:3000
    depends_on:
      - proxy
    labels:
      # Caddy labels for Isaiah web interface
      caddy: "https://monitor.dev.localhost"
      caddy.reverse_proxy: "{{upstreams 3000}}"
      caddy.basic_auth: "*"
      caddy.basic_auth.admin: "${MONITOR_BASIC_AUTH_HASH}"
      caddy.tls: "/certificates/dev.localhost.pem /certificates/dev.localhost-key.pem"
    # deploy:
    #   resources:
    #     limits:
    #       memory: 256M
    #       cpus: '0.3'
    #     reservations:
    #       memory: 128M
    #       cpus: '0.1'
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Redis - KV Storage & Document Status Storage
  kv:
    # ref: https://hub.docker.com/_/redis
    image: redis:8-alpine
    container_name: kv
    restart: unless-stopped
    user: "999:999"
    read_only: true
    labels:
      # Caddy labels for Redis web interface
      caddy: "https://kv.dev.localhost"
      caddy.reverse_proxy: "{{upstreams 6379}}"
    depends_on:
      - proxy
    tmpfs:
      - /tmp
      - /var/run
    env_file:
      - .env
      - .env.databases
    ports:
      - 6379:6379
    command: >
      redis-server  --appendonly yes --appendfsync everysec --save 900 1 --save 300 10 --save 60 10000 --maxmemory 1gb --maxmemory-policy allkeys-lru --tcp-keepalive 300 --timeout 300
    volumes:
      - redis_data:/data
    networks:
      - backend
    healthcheck:
      test: [ "CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Memgraph - Graph Storage
  graph:
    # ref: https://hub.docker.com/r/memgraph/memgraph-mage
    image: memgraph/memgraph-mage:latest
    container_name: graph
    restart: unless-stopped
    env_file:
      - .env
      - .env.databases
    command: >
      --log-level=WARNING --also-log-to-stderr=true --memory-limit=4096 --storage-properties-on-edges=true --storage-snapshot-interval-sec=300 --storage-wal-enabled=true --data-recovery-on-startup=true --telemetry-enabled=false
    volumes:
      - memgraph_data:/var/lib/memgraph
      - memgraph_log:/var/log/memgraph
    networks:
      - backend
    ports:
      - 7687:7687
    healthcheck:
      test: [ "CMD-SHELL", "echo 'RETURN 1;' | mgconsole --host 127.0.0.1 --port 7687 --use-ssl=false || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Memgraph Lab (Web UI for graph visualization)
  graph-ui:
    # ref: https://hub.docker.com/r/memgraph/lab
    image: memgraph/lab:3.5.0
    container_name: graph-ui
    restart: unless-stopped
    env_file:
      - .env
      - .env.databases
    networks:
      - backend
    ports:
      - 3090:3000
    labels:
      # Caddy labels for automatic subdomain routing
      caddy: "https://graph.dev.localhost"
      caddy.reverse_proxy: "{{upstreams 3000}}"
      # caddy.basic_auth: "*"
      # caddy.basic_auth.admin: "${MONITOR_BASIC_AUTH_HASH}"
      caddy.tls: "/certificates/dev.localhost.pem /certificates/dev.localhost-key.pem"
    depends_on:
      - proxy
      - graph
    healthcheck:
      test: timeout 10s bash -c ':> /dev/tcp/127.0.0.1/3000' || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Qdrant - Vector Storage
  vectors:
    # ref: https://hub.docker.com/r/qdrant/qdrant
    image: qdrant/qdrant:latest
    container_name: vectors
    restart: unless-stopped
    depends_on:
      - kv
    env_file:
      - .env
      - .env.databases
    volumes:
      - qdrant_storage:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
    networks:
      - backend
    ports:
      - 6333:6333
      - 6334:6334
    labels:
      # Caddy labels for automatic subdomain routing
      caddy: "https://vector.dev.localhost"
      caddy.reverse_proxy: "{{upstreams 6333}}"
      # caddy.basic_auth: "*"
      # caddy.basic_auth.admin: "${MONITOR_BASIC_AUTH_HASH}"
      caddy.tls: "/certificates/dev.localhost.pem /certificates/dev.localhost-key.pem"
    healthcheck:
      test: timeout 10s bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Light RAG
  rag:
    # ref: https://github.com/HKUDS/LightRAG/pkgs/container/lightrag
    image: ghcr.io/hkuds/lightrag:latest
    container_name: rag
    restart: unless-stopped
    depends_on:
      - proxy
      - kv
      - vectors
      - graph
    env_file:
      - .env
      - .env.lightrag
    environment:
      - LLM_BINDING_API_KEY=${LLM_BINDING_API_KEY}
      - EMBEDDING_BINDING_API_KEY=${EMBEDDING_BINDING_API_KEY}
    volumes:
      - lightrag_storage:/app/data/rag_storage
      - lightrag_inputs:/app/data/inputs
      - lightrag_logs:/app/logs
    networks:
      - frontend
      - backend
    ports:
      - 9080:9621
    labels:
      # Caddy labels for automatic subdomain routing
      caddy: "https://rag.dev.localhost"
      caddy.reverse_proxy: "{{upstreams 9621}}"
      # caddy.basic_auth: "*"
      # caddy.basic_auth.admin: "${MONITOR_BASIC_AUTH_HASH}"
      caddy.tls: "/certificates/dev.localhost.pem /certificates/dev.localhost-key.pem"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Open WebUI Frontend
  webui:
    # ref: https://github.com/open-webui/open-webui
    image: ghcr.io/open-webui/open-webui:main
    container_name: webui
    restart: unless-stopped
    depends_on:
      - proxy
      - rag
      - kv
      - vectors
    env_file:
      - .env
      - .env.openwebui
    environment:
      - DEFAULT_ADMIN_EMAIL=${DEFAULT_ADMIN_EMAIL:-admin@lightrag.local}
    volumes:
      - openwebui_data:/app/backend/data
    networks:
      - frontend
      - backend
    ports:
      - 3000:8080
    labels:
      # Caddy labels for automatic subdomain routing
      caddy: "https://webui.dev.localhost"
      caddy.reverse_proxy: "{{upstreams 8080}}"
      caddy.tls: "/certificates/dev.localhost.pem /certificates/dev.localhost-key.pem"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
          gateway: 172.20.0.1
  backend:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.21.0.0/24
          gateway: 172.21.0.1

volumes:
  # Caddy
  caddy_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      # Caddy will automatically create sub-folder 
      device: ./docker/data
  caddy_config:
    driver: local
    driver_opts:
      type: none
      o: bind
      # Caddy will automatically create sub-folder 
      device: ./docker/etc
  # Application Data
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/data/redis
  # Graph
  memgraph_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/data/memgraph
  memgraph_log:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/logs/memgraph
  # QDRANT Vector
  qdrant_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/data/qdrant/storage
  qdrant_snapshots:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/data/qdrant/snapshots
  # Rag
  lightrag_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/data/lightrag/storage
  lightrag_inputs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/data/lightrag/inputs
  lightrag_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/logs/lightrag
  # OpenWebUI Data
  openwebui_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./docker/data/openwebui
